
# ViT 学习笔记

## attention 基本思想

RNN --> LSTM --> GRU

* [RNN](https://motor.readthedocs.io/en/stable/index.html)


# Autoregressive


![RUNOOB 图标](https://github.com/kavinbj/vision_transformer_notebook/blob/main/imgs/attention01.jpg)


![RUNOOB 图标](https://pic4.zhimg.com/80/v2-3a88ac6c530170672781ae63ec695c83_1440w.jpg)

# multi-modality problem

# autoregressive decoder VS non-autoregressive decoder